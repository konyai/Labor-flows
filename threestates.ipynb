{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook calculates flow transition rates using the method from Konya (2018). The first part reads in data from Eurostat, using the [pandaSDMX](https://www.google.com) package.\n",
    "\n",
    "The second part calculates the flow rates. The idea is that every period there is a potential pool of searchers: those whose jobs just dissolved ($\\rho E_{t-1}$), those who were unemployed ($U_{t-1}$) and those who were inactive ($I_{t-1}$). Out of this pool, $\\lambda$ fraction searches for jobs. A fraction $f_t$ finds jobs within the period, the rest become unemployed.\n",
    "\n",
    "The flow rates $\\lambda_t$, $f_t$ and $\\rho_t$ can be identified from job tenure data. The key equations are the following (from KÃ³nya, 2018):\n",
    "\\begin{align}\n",
    "\\lambda_t f_t &= \\frac{e_t^s}{1-e_{t-1}} \\\\\n",
    "\\rho_t &= \\frac{1}{1-\\lambda_t f_t} \\left(1-\\frac{e_t-e_{t-1}^s}{e_t}\\right) \\\\\n",
    "\\lambda_t &= \\frac{i_t}{\\rho e_{t-1}+u_{t-1}+i_{t-1}}\n",
    "\\end{align}\n",
    "The calculations rely on the data series read in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Eurostat\n",
    "from pandasdmx import Request as rq\n",
    "import matplotlib.pyplot as plt\n",
    "estat = rq('ESTAT')\n",
    "\n",
    "# Import metadata for the required datasets\n",
    "meta1 = estat.datastructure('DSD_lfsq_ugan').write()\n",
    "meta2 = estat.datastructure('DSD_lfsq_igan').write()\n",
    "meta3 = estat.datastructure('DSD_lfsq_egdn2').write()\n",
    "meta4 = estat.datastructure('DSD_lfsq_ugad').write()\n",
    "meta5 = estat.datastructure('DSD_lfsi_long_q').write()\n",
    "meta6 = estat.datastructure('DSD_jvs_q_nace2').write()\n",
    "# meta1.codelist[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of unemployed\n",
    "resp1 = estat.data('lfsq_ugan', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64', 'CITIZEN': 'TOTAL'},params={'startPeriod': '2008'})\n",
    "u = resp1.write()\n",
    "u.columns = u.columns.get_level_values('GEO')\n",
    "u = u.sort_index(ascending='True')\n",
    "\n",
    "# Total number of inactive\n",
    "resp2 = estat.data('lfsq_igan', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64', 'CITIZEN': 'TOTAL'},params={'startPeriod': '2007'})\n",
    "inac = resp2.write()\n",
    "inac.columns = inac.columns.get_level_values('GEO')\n",
    "inac = inac.sort_index(ascending='True')\n",
    "\n",
    "# Employed by duration: first long term, next short term, finally no response\n",
    "resp3 = estat.data('lfsq_egdn2', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64','DURATION': 'M_GE3', 'NACE_R2': 'TOTAL'})\n",
    "el = resp3.write()\n",
    "el.columns = el.columns.get_level_values('GEO')\n",
    "el = el.sort_index(ascending='True')\n",
    "resp4 = estat.data('lfsq_egdn2', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64','DURATION': 'M_LT3', 'NACE_R2': 'TOTAL'})\n",
    "es = resp4.write()\n",
    "es.columns = el.columns.get_level_values('GEO')\n",
    "es = es.sort_index(ascending='True')\n",
    "resp5 = estat.data('lfsq_egdn2', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64','DURATION': 'NRP', 'NACE_R2': 'TOTAL'})\n",
    "enr = resp5.write()\n",
    "enr.columns = enr.columns.get_level_values('GEO')\n",
    "enr = enr.sort_index(ascending='True')\n",
    "\n",
    "# Unemployed by duration: first 1-2 month, next less than 1 month\n",
    "resp6 = estat.data('lfsq_ugad', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64', 'DURATION': 'M1-2'},params={'startPeriod': '2008'})\n",
    "us12 = resp6.write()\n",
    "us12.columns = us12.columns.get_level_values('GEO')\n",
    "us12 = us12.sort_index(ascending='True')\n",
    "resp7 = estat.data('lfsq_ugad', key={'FREQ': 'Q', 'SEX': 'T', 'AGE': 'Y15-64', 'DURATION': 'M_LT1'},params={'startPeriod': '2008'})\n",
    "usl1 = resp7.write()\n",
    "usl1.columns = usl1.columns.get_level_values('GEO')\n",
    "usl1 = usl1.sort_index(ascending='True')\n",
    "\n",
    "# Gross flows data lfsi_long_q\n",
    "flow = {}\n",
    "for s in ['E_E','E_I','E_U','I_E','I_I','I_U','U_E','U_I','U_U']:\n",
    "    resp = estat.data('lfsi_long_q', key={'FREQ': 'Q', 'UNIT': 'THS_PER', 'INDIC_EM': s, 'SEX': 'T'},params={'startPeriod': '2008'})\n",
    "    flow[s] = resp.write()\n",
    "    flow[s].columns = flow[s].columns.get_level_values('GEO')\n",
    "    flow[s] = flow[s].sort_index(ascending='True')\n",
    "    \n",
    "# Get vacancy data\n",
    "resp7 = estat.data('jvs_q_nace2', key={'FREQ': 'Q', 'S_ADJ': 'NSA', 'NACE_R2': 'A-S', 'SIZECLAS': 'TOTAL', 'INDIC_EM': 'JOBRATE'},params={'startPeriod': '2008'})\n",
    "v = resp7.write()\n",
    "v.columns = v.columns.get_level_values('GEO')\n",
    "v = v.sort_index(ascending='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two state model\n",
    "e = es+el\n",
    "e = e.sort_index(ascending='True')\n",
    "us = us12+usl1\n",
    "us = us.sort_index(ascending='True')\n",
    "em = e/(e+u)\n",
    "em = em.sort_index(ascending='True')\n",
    "ems = es/(e+u)\n",
    "ems = ems.sort_index(ascending='True')\n",
    "un = u/(e+u)\n",
    "uns = us/(e+u)\n",
    "fu = 1-(un-uns)/un.shift(1)\n",
    "rhou = (uns/em.shift(1))/(1-fu)\n",
    "fe = ems/un.shift(1)\n",
    "rhoe = (1-(em-ems)/em.shift(1))/(1-fe)\n",
    "\n",
    "# Three state model\n",
    "pop = inac+e+u\n",
    "inr = inac/pop\n",
    "er = e/pop\n",
    "esr = es/pop\n",
    "ur = u/pop\n",
    "lf = esr/(1-er.shift(1))\n",
    "rho = (1-(er-esr)/er.shift(1))/(1-lf)\n",
    "lamb = 1-inr/(1-(1-rho)*er.shift(1))\n",
    "f = lf/lamb\n",
    "s = lamb*(1-(1-rho)*er.shift(1))\n",
    "\n",
    "# Rates from gross flow data\n",
    "f_ue = flow['U_E']/(flow['U_U']+flow['U_E']+flow['U_I'])\n",
    "rho_eui = (flow['E_U']+flow['E_I'])/(flow['E_E']+flow['E_U']+flow['E_I'])\n",
    "lambda_gf = (flow['I_E']+flow['I_U'])/(flow['I_E']+flow['I_U']+flow['I_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Job finding rates for the UK\n",
    "p1 = pd.concat([f['UK'],fu['UK'],fe['UK'],f_ue['UK']],axis = 1)\n",
    "p1.plot(kind='line')\n",
    "plt.legend(['Three states','Two states (U)','Two states (E)','UE flow rate'])\n",
    "plt.ylabel('Job finding rates')\n",
    "plt.xlabel('')\n",
    "plt.title('United Kingdom')\n",
    "plt.savefig('f_uk.eps',dpi=600)\n",
    "\n",
    "# Job finding rates for France\n",
    "p1 = pd.concat([f['FR'],fu['FR'],fe['FR'],f_ue['FR']],axis = 1)\n",
    "p1.plot(kind='line')\n",
    "plt.legend(['Three states','Two states (U)','Two states (E)','UE flow rate'])\n",
    "plt.ylabel('Job finding rates')\n",
    "plt.xlabel('')\n",
    "plt.title('France')\n",
    "plt.savefig('f_fr.eps',dpi=600)\n",
    "\n",
    "# Job finding rates for Poland\n",
    "p1 = pd.concat([f['PL'],fu['PL'],fe['PL'],f_ue['PL']],axis = 1)\n",
    "p1.plot(kind='line')\n",
    "plt.legend(['Three states','Two states (U)','Two states (E)','UE flow rate'])\n",
    "plt.ylabel('Job finding rates')\n",
    "plt.xlabel('')\n",
    "plt.title('Poland')\n",
    "plt.savefig('f_pl.eps',dpi=600)\n",
    "\n",
    "# Job finding rates for Poland\n",
    "p1 = pd.concat([f['SE'],fu['SE'],fe['SE'],f_ue['SE']],axis = 1)\n",
    "p1.plot(kind='line')\n",
    "plt.legend(['Three states','Two states (U)','Two states (E)','UE flow rate'])\n",
    "plt.ylabel('Job finding rates')\n",
    "plt.xlabel('')\n",
    "plt.title('Sweden')\n",
    "plt.savefig('f_se.eps',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-11c00b73fd49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Estimate using unemployed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtheta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mur\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ur' is not defined"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "import numpy as np\n",
    "\n",
    "# Estimate using searchers\n",
    "theta = v/s\n",
    "endog = np.log(f['HU'][1:].values)\n",
    "exog = np.log(theta['HU'][1:].values)\n",
    "mod1 = sm.OLS(endog, sm.add_constant(exog),missing = 'drop')\n",
    "res1 = mod1.fit()\n",
    "#print(res1.summary())\n",
    "\n",
    "# Estimate using unemployed\n",
    "theta2 = v/ur\n",
    "endog = np.log(f['HU'][1:].values)\n",
    "exog = np.log(theta2['HU'][1:].values)\n",
    "mod2 = sm.OLS(endog, sm.add_constant(exog),missing = 'drop')\n",
    "res2 = mod2.fit()\n",
    "#print(res2.summary())\n",
    "\n",
    "# Export results\n",
    "dfoutput = summary_col([res1,res2],stars=True)\n",
    "print(dfoutput)\n",
    "tabl = open('myreg.tex', 'w')\n",
    "tabl.write(dfoutput.as_latex())\n",
    "tabl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
